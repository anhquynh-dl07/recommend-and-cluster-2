import streamlit as st
import pandas as pd
import numpy as np
import pickle
import joblib
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

# ==========================================================
# 1. CACHED LOADERS
# ==========================================================

@st.cache_resource
def load_models():
    with open('xe_cosine_sim.pkl', 'rb') as f:
        cosine_sim = pickle.load(f)

    vectorizer = joblib.load("tfidf_vectorizer.pkl")

    with open('tfidf_matrix.pkl', 'rb') as f:
        tfidf_matrix = pickle.load(f)

    with open("kmeans.pkl", "rb") as f:
        kmeans = pickle.load(f)

    with open("scaler.pkl", "rb") as f:
        scaler = pickle.load(f)

    with open("pca.pkl", "rb") as f:
        pca = pickle.load(f)

    return cosine_sim, vectorizer, tfidf_matrix, kmeans, scaler, pca


@st.cache_data
def load_and_clean_data():
    # Load & rename columns
    data = pd.read_excel('data_motobikes.xlsx').rename(columns={
        'Ti√™u ƒë·ªÅ': 'title',
        'ƒê·ªãa ch·ªâ': 'address',
        'M√¥ t·∫£ chi ti·∫øt': 'description',
        'Gi√°': 'price',
        'Kho·∫£ng gi√° min': 'min_price',
        'Kho·∫£ng gi√° max': 'max_price',
        'Th∆∞∆°ng hi·ªáu': 'brand',
        'D√≤ng xe': 'model',
        'NƒÉm ƒëƒÉng k√Ω': 'registration_year',
        'S·ªë Km ƒë√£ ƒëi': 'mileage_km',
        'T√¨nh tr·∫°ng': 'condition',
        'Lo·∫°i xe': 'bike_type',
        'Dung t√≠ch xe': 'engine_capacity',
        'Xu·∫•t x·ª©': 'origin',
        'Ch√≠nh s√°ch b·∫£o h√†nh': 'warranty_policy',
        'Tr·ªçng l∆∞·ª£ng': 'weight'
    })

    df = data.copy()
    df1 = data.copy()

    # ============= CLEANING df1 FOR CLUSTERING =============
    cols_drop = ['title', 'address', 'description', 'Href']
    df1 = df1.drop(columns=[c for c in cols_drop if c in df1.columns], errors='ignore')
    df1 = df1.drop(columns=['warranty_policy', 'weight', 'condition'], errors='ignore')
    df1 = df1.dropna()

    # Clean price
    df1['price'] = (
        df1['price'].astype(str)
        .str.replace('[^0-9]', '', regex=True)
        .replace('', np.nan).astype(float)
    )

    def parse_price(s):
        if pd.isna(s): return np.nan
        s = str(s).lower().replace("tr", "").replace(" ", "")
        try: return float(s) * 1_000_000
        except: return np.nan

    df1['min_price'] = df1['min_price'].apply(parse_price)
    df1['max_price'] = df1['max_price'].apply(parse_price)

    df1 = df1[~(df1['price'] == 0)]

    # Remove invalid engine_capacity
    df1 = df1[~df1['engine_capacity'].astype(str).str.contains("Nh·∫≠t B·∫£n", na=False)]

    # Clean origin
    df1 = df1[~df1['origin'].astype(str).str.contains('B·∫£o h√†nh h√£ng', case=False, na=False)]
    df1['origin'] = df1['origin'].replace(['ƒêang c·∫≠p nh·∫≠t', 'N∆∞·ªõc kh√°c'], 'N∆∞·ªõc kh√°c')

    # Registration year
    df1['registration_year'] = (
        df1['registration_year'].astype(str)
        .str.lower()
        .str.replace('tr∆∞·ªõc nƒÉm', '1980')
        .str.extract('(\d{4})')[0]
    ).astype(float)

    df1.loc[(df1['registration_year'] < 1980) | (df1['registration_year'] > 2025),
            'registration_year'] = np.nan

    df1["age"] = 2025 - df1["registration_year"]

    # Log transforms
    numeric_cols = ['age', 'mileage_km', 'min_price', 'max_price', 'price']
    for c in numeric_cols:
        df1[f"log_{c}"] = np.log1p(df1[c])

    df1 = df1.dropna(subset=numeric_cols)

    return df, df1


@st.cache_data
def compute_clusters(df1):
    # models are accessed from global scope:
    global scaler, kmeans, pca

    num_cols = ['age', 'mileage_km', 'min_price', 'max_price', 'log_price']

    X_scaled = scaler.transform(df1[num_cols])
    df1['cluster_label'] = kmeans.predict(X_scaled)

    pca_points = pca.transform(X_scaled)
    df1['x'] = pca_points[:, 0]
    df1['y'] = pca_points[:, 1]

    return df1, num_cols

# ==========================================================
# LOAD EVERYTHING (CACHED)
# ==========================================================
cosine_sim, vectorizer, tfidf_matrix, kmeans, scaler, pca = load_models()
df, df1 = load_and_clean_data()
df1, num_cols = compute_clusters(df1)



# ==========================================================
# FUNCTIONS
# ==========================================================
def get_similar_bikes(title, top_n=5):
    idx = df.index[df["title"] == title][0]
    scores = sorted(list(enumerate(cosine_sim[idx])), key=lambda x: x[1], reverse=True)
    return [df.iloc[i[0]]["title"] for i in scores[1:top_n+1]]


def search_by_keyword(keyword, top_n=5):
    keyword_vec = vectorizer.transform([keyword])
    sim_scores = cosine_similarity(keyword_vec, tfidf_matrix).flatten()
    df["score"] = sim_scores
    return df.sort_values(by="score", ascending=False).head(top_n)["title"].tolist()


def preprocess_user_input(price, min_price, max_price, mileage_km, registration_year):
    age = 2025 - registration_year
    log_price = np.log1p(price)
    X = np.array([[age, mileage_km, min_price, max_price, log_price]])
    return scaler.transform(X)


# ==========================================================
# STREAMLIT PAGES
# ==========================================================
st.sidebar.title("üöó Motorbike Recommendation and Clustering")
page = st.sidebar.selectbox("Menu", ["Home", "Recommendation system", "Clustering analysis"])


if page == "Home":
    st.title("Motorbike Data Science Project")
    # st.write("H·ªá th·ªëng g·ª£i √Ω v√† ph√¢n c·ª•m xe m√°y.")

    st.header('Gi·ªõi thi·ªáu d·ª± √°n')
    st.text('''ƒê√¢y l√† Project 2 trong kh√≥a ƒë·ªì √°n t·ªët nghi·ªáp Data Science and Machine Learning 2024 l·ªõp DL07_K308 c·ªßa nh√≥m 6. \nTh√†nh vi√™n nh√≥m g·ªìm c√≥:
        \n1. V≈© Th·ªã Ng·ªçc Anh \n2. Nguy·ªÖn Ph·∫°m Qu·ª≥nh Anh''')
    st.write("""### C√≥ 2 ch·ªß ƒë·ªÅ trong kh√≥a h·ªçc:    
- Topic 1: D·ª± ƒëo√°n gi√° xe m√°y c≈©, ph√°t hi·ªán xe m√°y b·∫•t th∆∞·ªùng
- Topic 2: H·ªá th·ªëng g·ª£i √Ω xe m√°y d·ª±a tr√™n n·ªôi dung, ph√¢n c·ª•m xe m√°y
            """)
    
    st.header('M·ª•c ti√™u c·ªßa d·ª± √°n')
    # st.text('''1. T·∫°o m√¥ h√¨nh ƒë·ªÅ xu·∫•t xe m√°y t∆∞∆°ng t·ª± ƒë·ªëi v·ªõi m·∫´u xe ƒë∆∞·ª£c ch·ªçn ho·∫∑c t·ª´ kh√≥a t√¨m ki·∫øm do ng∆∞·ªùi d√πng cung c·∫•p.\n2. Ph√¢n kh√∫c th·ªã tr∆∞·ªùng xe m√°y''')
    st.write("""
M·ª•c ti√™u d·ª± √°n:
- T·∫°o m√¥ h√¨nh g·ª£i √Ω xe m√°y t∆∞∆°ng t·ª± d·ª±a tr√™n m·∫´u xe ƒë∆∞·ª£c ch·ªçn ho·∫∑c t·ª´ kh√≥a ng∆∞·ªùi d√πng cung c·∫•p, gi√∫p h·ªó tr·ª£ t√¨m ki·∫øm v√† l·ª±a ch·ªçn xe ph√π h·ª£p.
- Ph√¢n kh√∫c th·ªã tr∆∞·ªùng xe m√°y d·ª±a tr√™n d·ªØ li·ªáu thu th·∫≠p ƒë∆∞·ª£c, nh·∫±m nh·∫≠n di·ªán c√°c nh√≥m xe ƒë·∫∑c tr∆∞ng theo gi√°, th∆∞∆°ng hi·ªáu, ph√¢n kh·ªëi v√† nhu c·∫ßu ng∆∞·ªùi d√πng.
""")



    st.header("Thu th·∫≠p d·ªØ li·ªáu")

    st.markdown("""
    **D·ªØ li·ªáu xe m√°y ƒë√£ qua s·ª≠ d·ª•ng** ƒë∆∞·ª£c thu th·∫≠p t·ª´ n·ªÅn t·∫£ng **Ch·ª£ T·ªët**  
    (tr∆∞·ªõc ng√†y 01/07/2025).  

    B·ªô d·ªØ li·ªáu bao g·ªìm c√°c th√¥ng tin sau:

    - **id**: s·ªë th·ª© t·ª± c·ªßa s·∫£n ph·∫©m trong b·ªô d·ªØ li·ªáu  
    - **Ti√™u ƒë·ªÅ**: t·ª±a ƒë·ªÅ b√†i ƒëƒÉng b√°n s·∫£n ph·∫©m  
    - **Gi√°**: gi√° b√°n c·ªßa xe m√°y  
    - **Kho·∫£ng gi√° min**: gi√° s√†n ∆∞·ªõc t√≠nh c·ªßa xe m√°y  
    - **Kho·∫£ng gi√° max**: gi√° tr·∫ßn ∆∞·ªõc t√≠nh c·ªßa xe m√°y  
    - **ƒê·ªãa ch·ªâ**: ƒë·ªãa ch·ªâ giao d·ªãch (ph∆∞·ªùng, qu·∫≠n, th√†nh ph·ªë H·ªì Ch√≠ Minh)  
    - **M√¥ t·∫£ chi ti·∫øt**: m√¥ t·∫£ th√™m v·ªÅ s·∫£n ph·∫©m ‚Äî ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t, t√¨nh tr·∫°ng, th√¥ng tin kh√°c  
    - **Th∆∞∆°ng hi·ªáu**: h√£ng s·∫£n xu·∫•t (Honda, Yamaha, Piaggio, SYM‚Ä¶)  
    - **D√≤ng xe**: d√≤ng xe c·ª• th·ªÉ (Air Blade, Vespa, Exciter, LEAD, Vario, ‚Ä¶)  
    - **NƒÉm ƒëƒÉng k√Ω**: nƒÉm ƒëƒÉng k√Ω l·∫ßn ƒë·∫ßu c·ªßa xe  
    - **S·ªë km ƒë√£ ƒëi**: s·ªë kilomet xe ƒë√£ v·∫≠n h√†nh  
    - **T√¨nh tr·∫°ng**: t√¨nh tr·∫°ng hi·ªán t·∫°i (v√≠ d·ª•: ƒë√£ s·ª≠ d·ª•ng)  
    - **Lo·∫°i xe**: Xe s·ªë, Tay ga, Tay c√¥n/Moto  
    - **Dung t√≠ch xe**: dung t√≠ch xi-lanh (v√≠ d·ª•: D∆∞·ªõi 50cc, 50‚Äì100cc, 100‚Äì175cc, ‚Ä¶)  
    - **Xu·∫•t x·ª©**: qu·ªëc gia s·∫£n xu·∫•t (Vi·ªát Nam, ƒê√†i Loan, Nh·∫≠t B·∫£n, ...)  
    - **Ch√≠nh s√°ch b·∫£o h√†nh**: th√¥ng tin b·∫£o h√†nh n·∫øu c√≥  
    - **Tr·ªçng l∆∞·ª£ng**: tr·ªçng l∆∞·ª£ng ∆∞·ªõc t√≠nh c·ªßa xe  
    - **Href**: ƒë∆∞·ªùng d·∫´n t·ªõi b√†i ƒëƒÉng s·∫£n ph·∫©m  
    """)


    # with open("data/data_motobikes.xlsx", "rb") as f:
    #     st.download_button(
    #         label="üì• T·∫£i xu·ªëng d·ªØ li·ªáu xe m√°y (Excel)",
    #         data=f,
    #         file_name="data_motobikes.xlsx",
    #         mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    #     )


elif page == "Recommendation system":
    st.title("Recommendation system")
    # theo xe c√≥ s·∫µn
    st.header("G·ª£i √Ω xe theo m·∫´u c√≥ s·∫µn")
    selected = st.selectbox("Ch·ªçn m·∫´u xe:", df["title"])

    if st.button("G·ª£i √Ω"):
        similar_titles = get_similar_bikes(selected)

        # Filter dataframe to only the similar bikes
        result_df = df[df["title"].isin(similar_titles)][
            ["id", "title", "brand", "model", "price", "registration_year"]
        ]

        st.dataframe(result_df, width='stretch')
        
    # theo t·ª´ kh√≥a
    st.header("T√¨m ki·∫øm theo t·ª´ kh√≥a")
    keyword = st.text_input("Nh·∫≠p t·ª´ kh√≥a")
    if st.button("T√¨m xe t∆∞∆°ng t·ª±") and keyword.strip():
        similar_titles = search_by_keyword(keyword)

        # Filter dataframe to only the similar bikes
        result_search_df = df[df["title"].isin(similar_titles)][
            ["id", "title", "brand", "model", "price", "registration_year"]
        ]

        st.dataframe(result_search_df, width='stretch')

elif page == "Clustering analysis":
    st.title("K-Means Motorbike Clustering")

    st.write('''Trong 3 m√¥ h√¨nh ph√¢n c·ª•m KMeans, Bisect KMeans v√† Agglomerate th√¨ KMeans v·ªõi k = 3 cho k·∫øt qu·∫£ ph√¢n c·ª•m t·ªët nh·∫•t.
               \nM√¥ h√¨nh ph√¢n c·ª•m xe ƒë∆∞·ª£c ch·ªçn l√† KMeans v·ªõi k = 3.''')
    st.write("Tr·ª±c quan h√≥a k·∫øt qu·∫£ ph√¢n c·ª•m v·ªõi PCA:")

    # ====== PLOT PCA CLUSTERS ======
    fig, ax = plt.subplots(figsize=(5, 4))
    ax.scatter(df1["x"], df1["y"], c=df1["cluster_label"], s=10)
    ax.set_title("PCA Visualization")
    st.pyplot(fig)

    # ====== CLUSTER SUMMARY ======
    # st.subheader("Th·ªëng k√™ theo t·ª´ng c·ª•m:")

    # cluster_summary = (
    #     df1.groupby('cluster_label')
    #        .agg(
    #            count=('cluster_label', 'size'),
    #            avg_price=('price', 'mean'),
    #            avg_age=('age', 'mean'),
    #            avg_mileage=('mileage_km', 'mean')
    #        )
    #        .sort_values('avg_price')
    # )

    # st.dataframe(cluster_summary, width='stretch')

    st.subheader("Th·ªëng k√™ theo t·ª´ng c·ª•m:")

    cluster_summary = (
        df1.groupby('cluster_label')
        .agg(
            count=('cluster_label', 'size'),
            avg_price=('price', 'mean'),
            avg_age=('age', 'mean'),
            avg_mileage=('mileage_km', 'mean')
        )
        .sort_values('avg_price')
    )

    # ƒê·ªïi t√™n c·ªôt
    cluster_summary = cluster_summary.rename(columns={
        "count": "S·ªë l∆∞·ª£ng (xe)",
        "avg_price": "Gi√° trung b√¨nh (VND)",
        "avg_age": "Tu·ªïi trung b√¨nh (nƒÉm)",
        "avg_mileage": "S·ªë km trung b√¨nh (km)"
    })

    # Format s·ªë nguy√™n v√† th√™m d·∫•u ph·∫©y
    cluster_summary["Gi√° trung b√¨nh (VND)"] = (
        cluster_summary["Gi√° trung b√¨nh (VND)"]
            .round(0).astype(int)
            .map(lambda x: f"{x:,}")
    )

    cluster_summary["S·ªë km trung b√¨nh (km)"] = (
        cluster_summary["S·ªë km trung b√¨nh (km)"]
            .round(0).astype(int)
            .map(lambda x: f"{x:,}")
    )

    st.dataframe(cluster_summary, width='stretch')


    st.subheader("T√≥m t·∫Øt √Ω nghƒ©a t·ª´ng c·ª•m:")

    st.markdown("""
    - **C·ª•m 0:** Xe ph·ªï th√¥ng ‚Äì gi√° r·∫ª, tu·ªïi xe trung b√¨nh, s·ªë km trung b√¨nh ‚Üí **nh√≥m chi·∫øm th·ªã ph·∫ßn l·ªõn nh·∫•t**.
    - **C·ª•m 1:** Xe m·ªõi h∆°n ‚Äì gi√° cao h∆°n, ch·∫°y √≠t h∆°n ‚Üí **ph√¢n kh√∫c ch·∫•t l∆∞·ª£ng t·ªët**.
    - **C·ª•m 2:** Xe r·∫•t c≈© ‚Äì gi√° th·∫•p nh·∫•t, s·ªë km c·ª±c cao ‚Üí **ph√¢n kh√∫c xu·ªëng c·∫•p ho·∫∑c d·ªØ li·ªáu km kh√¥ng ch√≠nh x√°c**.
    """)

    bike_labels = {0: "Xe ph·ªï th√¥ng gi√° r·∫ª",
                   1: "Xe t∆∞∆°ng ƒë·ªëi m·ªõi",
                   2: "Xe c≈© xu·ªëng c·∫•p ho·∫∑c d·ªØ li·ªáu cung c·∫•p kh√¥ng ch√≠nh x√°c"}


    # ====== CLUSTER NEW BIKE ======
    st.subheader("Ph√¢n c·ª•m xe m·ªõi")

    st.write("Vui l√≤ng nh·∫≠p c√°c th√¥ng s·ªë c·ªßa xe c·∫ßn x√°c ƒë·ªãnh")

    price = st.number_input("Gi√° xe (VND)", min_value=500_000, step=100_000)
    min_price = st.number_input("Kho·∫£ng gi√° min", min_value=500_000, step=100_000)
    max_price = st.number_input("Kho·∫£ng gi√° max", min_value=500_000, step=100_000)
    mileage_km = st.number_input("S·ªë km ƒë√£ ƒëi", min_value=0, step=100)
    registration_year = st.slider("NƒÉm ƒëƒÉng k√Ω", 1980, 2025)

    if st.button("Ph√¢n c·ª•m"):
        X_new = preprocess_user_input(price, min_price, max_price, mileage_km, registration_year)
        cluster = int(kmeans.predict(X_new)[0])
        st.success(f"Xe thu·ªôc c·ª•m s·ªë **{cluster}**")

        st.write(bike_labels.get(cluster, "Kh√¥ng c√≥ m√¥ t·∫£ cho c·ª•m n√†y"))
