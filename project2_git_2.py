import streamlit as st
import pandas as pd
import numpy as np
import pickle
import joblib
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

# ==========================================================
# 1. CACHED LOADERS
# ==========================================================

@st.cache_resource
def load_models():
    with open('xe_cosine_sim.pkl', 'rb') as f:
        cosine_sim = pickle.load(f)

    vectorizer = joblib.load("tfidf_vectorizer.pkl")

    with open('tfidf_matrix.pkl', 'rb') as f:
        tfidf_matrix = pickle.load(f)

    with open("kmeans.pkl", "rb") as f:
        kmeans = pickle.load(f)

    with open("scaler.pkl", "rb") as f:
        scaler = pickle.load(f)

    with open("pca.pkl", "rb") as f:
        pca = pickle.load(f)

    return cosine_sim, vectorizer, tfidf_matrix, kmeans, scaler, pca


@st.cache_data
def load_and_clean_data():
    # Load & rename columns
    data = pd.read_excel('data_motobikes.xlsx').rename(columns={
        'Ti√™u ƒë·ªÅ': 'title',
        'ƒê·ªãa ch·ªâ': 'address',
        'M√¥ t·∫£ chi ti·∫øt': 'description',
        'Gi√°': 'price',
        'Kho·∫£ng gi√° min': 'min_price',
        'Kho·∫£ng gi√° max': 'max_price',
        'Th∆∞∆°ng hi·ªáu': 'brand',
        'D√≤ng xe': 'model',
        'NƒÉm ƒëƒÉng k√Ω': 'registration_year',
        'S·ªë Km ƒë√£ ƒëi': 'mileage_km',
        'T√¨nh tr·∫°ng': 'condition',
        'Lo·∫°i xe': 'bike_type',
        'Dung t√≠ch xe': 'engine_capacity',
        'Xu·∫•t x·ª©': 'origin',
        'Ch√≠nh s√°ch b·∫£o h√†nh': 'warranty_policy',
        'Tr·ªçng l∆∞·ª£ng': 'weight'
    })

    df = data.copy()
    df1 = data.copy()

    # ============= CLEANING df1 FOR CLUSTERING =============
    cols_drop = ['title', 'address', 'description', 'Href']
    df1 = df1.drop(columns=[c for c in cols_drop if c in df1.columns], errors='ignore')
    df1 = df1.drop(columns=['warranty_policy', 'weight', 'condition'], errors='ignore')
    df1 = df1.dropna()

    # Clean price
    df1['price'] = (
        df1['price'].astype(str)
        .str.replace('[^0-9]', '', regex=True)
        .replace('', np.nan).astype(float)
    )

    def parse_price(s):
        if pd.isna(s): return np.nan
        s = str(s).lower().replace("tr", "").replace(" ", "")
        try: return float(s) * 1_000_000
        except: return np.nan

    df1['min_price'] = df1['min_price'].apply(parse_price)
    df1['max_price'] = df1['max_price'].apply(parse_price)

    df1 = df1[~(df1['price'] == 0)]

    # Remove invalid engine_capacity
    df1 = df1[~df1['engine_capacity'].astype(str).str.contains("Nh·∫≠t B·∫£n", na=False)]

    # Clean origin
    df1 = df1[~df1['origin'].astype(str).str.contains('B·∫£o h√†nh h√£ng', case=False, na=False)]
    df1['origin'] = df1['origin'].replace(['ƒêang c·∫≠p nh·∫≠t', 'N∆∞·ªõc kh√°c'], 'N∆∞·ªõc kh√°c')

    # Registration year
    df1['registration_year'] = (
        df1['registration_year'].astype(str)
        .str.lower()
        .str.replace('tr∆∞·ªõc nƒÉm', '1980')
        .str.extract('(\d{4})')[0]
    ).astype(float)

    df1.loc[(df1['registration_year'] < 1980) | (df1['registration_year'] > 2025),
            'registration_year'] = np.nan

    df1["age"] = 2025 - df1["registration_year"]

    # Log transforms
    numeric_cols = ['age', 'mileage_km', 'min_price', 'max_price', 'price']
    for c in numeric_cols:
        df1[f"log_{c}"] = np.log1p(df1[c])

    df1 = df1.dropna(subset=numeric_cols)

    return df, df1


@st.cache_data
def compute_clusters(df1):
    # models are accessed from global scope:
    global scaler, kmeans, pca

    num_cols = ['age', 'mileage_km', 'min_price', 'max_price', 'log_price']

    X_scaled = scaler.transform(df1[num_cols])
    df1['cluster_label'] = kmeans.predict(X_scaled)

    pca_points = pca.transform(X_scaled)
    df1['x'] = pca_points[:, 0]
    df1['y'] = pca_points[:, 1]

    return df1, num_cols

# ==========================================================
# LOAD EVERYTHING (CACHED)
# ==========================================================
cosine_sim, vectorizer, tfidf_matrix, kmeans, scaler, pca = load_models()
df, df1 = load_and_clean_data()
df1, num_cols = compute_clusters(df1)



# ==========================================================
# FUNCTIONS
# ==========================================================
def get_similar_bikes(title, top_n=5):
    idx = df.index[df["title"] == title][0]
    scores = sorted(list(enumerate(cosine_sim[idx])), key=lambda x: x[1], reverse=True)
    return [df.iloc[i[0]]["title"] for i in scores[1:top_n+1]]


def search_by_keyword(keyword, top_n=5):
    keyword_vec = vectorizer.transform([keyword])
    sim_scores = cosine_similarity(keyword_vec, tfidf_matrix).flatten()
    df["score"] = sim_scores
    return df.sort_values(by="score", ascending=False).head(top_n)["title"].tolist()


def preprocess_user_input(price, min_price, max_price, mileage_km, registration_year):
    age = 2025 - registration_year
    log_price = np.log1p(price)
    X = np.array([[age, mileage_km, min_price, max_price, log_price]])
    return scaler.transform(X)


# ==========================================================
# STREAMLIT PAGES
# ==========================================================
# st.set_page_config(page_title="Motorbike Recommendation and Motorbike Segmentation by Clustering", layout="wide")
# st.title("Motorbike Recommendation and Motorbike Segmentation by Clustering")

menu = ["Gi·ªõi thi·ªáu", "B√†i to√°n nghi·ªáp v·ª•", "ƒê√°nh gi√° m√¥ h√¨nh v√† B√°o c√°o", "G·ª£i √Ω m·∫´u xe t∆∞∆°ng t·ª±", "Ph√¢n c·ª•m ph√¢n kh√∫c xe m√°y"]
page = st.sidebar.selectbox('Menu', menu)


if page == 'Gi·ªõi thi·ªáu':
    st.title("H·ªá th·ªëng g·ª£i √Ω xe m√°y t∆∞∆°ng t·ª± v√† ph√¢n c·ª•m xe m√°y")
    # st.markdown("·ª®ng d·ª•ng cho ph√©p: \n1) G·ª£i √Ω m·∫´u xe m√°y t∆∞∆°ng t·ª± (nh·∫≠p th√¥ng s·ªë xe) \n2) X√°c ƒë·ªãnh ph√¢n kh√∫c xe m√°y b·∫±ng ph∆∞∆°ng ph√°p ph√¢n c·ª•m (nh·∫≠p th√¥ng s·ªë ho·∫∑c upload file)")
    st.image("xe_may_cu.jpg", caption="Xe m√°y c≈©")
    st.subheader("[Trang ch·ªß Ch·ª£ T·ªët](https://www.chotot.com/)")
    
    st.header('Gi·ªõi thi·ªáu d·ª± √°n')
    st.markdown('''ƒê√¢y l√† d·ª± √°n x√¢y d·ª±ng h·ªá th·ªëng h·ªó tr·ª£ **g·ª£i √Ω m·∫´u xe m√°y t∆∞∆°ng t·ª±** v√† **ph√¢n kh√∫c xe m√°y b·∫±ng ph∆∞∆°ng ph√°p ph√¢n c·ª•m** tr√™n n·ªÅn t·∫£ng *Ch·ª£ T·ªët* - trong kh√≥a ƒë·ªì √°n t·ªët nghi·ªáp Data Science and Machine Learning 2024 l·ªõp DL07_K308 c·ªßa nh√≥m 6. \nTh√†nh vi√™n nh√≥m g·ªìm c√≥:
        \n1. V≈© Th·ªã Ng·ªçc Anh \n2. Nguy·ªÖn Ph·∫°m Qu·ª≥nh Anh''')
    
    st.header('M·ª•c ti√™u c·ªßa d·ª± √°n')
    # st.text('''1. T·∫°o m√¥ h√¨nh ƒë·ªÅ xu·∫•t xe m√°y t∆∞∆°ng t·ª± ƒë·ªëi v·ªõi m·∫´u xe ƒë∆∞·ª£c ch·ªçn ho·∫∑c t·ª´ kh√≥a t√¨m ki·∫øm do ng∆∞·ªùi d√πng cung c·∫•p.\n2. Ph√¢n kh√∫c th·ªã tr∆∞·ªùng xe m√°y b·∫±ng ph∆∞∆°ng ph√°p ph√¢n c·ª•m''')
    st.markdown("""
        ### M·ª•c ti√™u c·ªßa d·ª± √°n:
        **1. X√¢y d·ª±ng m√¥ h√¨nh ƒë·ªÅ xu·∫•t th√¥ng minh:**
        - ƒê·ªÅ xu·∫•t c√°c m·∫´u xe m√°y t∆∞∆°ng ƒë·ªìng cho m·ªôt m·∫´u ƒë∆∞·ª£c ch·ªçn ho·∫∑c theo t·ª´ kh√≥a t√¨m ki·∫øm c·ªßa ng∆∞·ªùi d√πng.
        - K·∫øt h·ª£p nhi·ªÅu ngu·ªìn th√¥ng tin (th√¥ng s·ªë k·ªπ thu·∫≠t, h√¨nh ·∫£nh, m√¥ t·∫£, gi√°, ƒë√°nh gi√°) ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c.
             
        **2. Ph√¢n kh√∫c th·ªã tr∆∞·ªùng xe m√°y:**
        - Ph√¢n lo·∫°i s·∫£n ph·∫©m theo nh√≥m theo t·ªáp gi√°, tu·ªïi xe, kho·∫£ng gi√° t·ªëi thi·ªÉu/ t·ªëi ƒëa, 
        gi√∫p cho vi·ªác ƒë·ªãnh gi√° xe hi·ªáu qu·∫£ h∆°n v√† chi·∫øn l∆∞·ª£c marketing hi·ªáu qu·∫£ h∆°n.
        """)

    st.subheader('Ph√¢n c√¥ng c√¥ng vi·ªác')
    st.write("""
        - X·ª≠ l√Ω d·ªØ li·ªáu: Ng·ªçc Anh v√† Qu·ª≥nh Anh
        - G·ª£i √Ω xe m√°y b·∫±ng Gensim: Qu·ª≥nh Anh
        - G·ª£i √Ω xe m√°y b·∫±ng Cosine similarity: Ng·ªçc Anh
        - Ph√¢n kh√∫c xe m√°y b·∫±ng ph∆∞∆°ng ph√°p ph√¢n c·ª•m: Ng·ªçc Anh
        - L√†m slide: Ng·ªçc Anh v√† Qu·ª≥nh Anh
        - Giao di·ªán streamlit: Qu·ª≥nh Anh

        """)
    
elif page == "B√†i to√°n nghi·ªáp v·ª•":
    st.header("B√†i to√°n nghi·ªáp v·ª•")

    st.markdown("""

        ### V·∫•n ƒë·ªÅ nghi·ªáp v·ª•
        - Ng∆∞·ªùi d√πng g·∫∑p kh√≥ khƒÉn khi t√¨m xe ph√π h·ª£p trong h√†ng trƒÉm l·ª±a ch·ªçn.
        - Ch∆∞a c√≥ h·ªá th·ªëng g·ª£i √Ω xe t∆∞∆°ng t·ª± khi ng∆∞·ªùi d√πng ch·ªçn m·ªôt m·∫´u c·ª• th·ªÉ ho·∫∑c t√¨m ki·∫øm theo t·ª´ kh√≥a.
        - Th·ªã tr∆∞·ªùng xe m√°y r·∫•t ƒëa d·∫°ng ‚Üí kh√≥ nh·∫≠n di·ªán c√°c ph√¢n kh√∫c r√µ r√†ng.
        - C·∫ßn h·ªá th·ªëng g·ª£i √Ω & ph√¢n kh√∫c t·ª± ƒë·ªông ƒë·ªÉ h·ªó tr·ª£ ng∆∞·ªùi d√πng v√† ƒë·ªôi ng≈© ph√¢n t√≠ch.


        ### B√†i to√°n ƒë·∫∑t ra
        - X√¢y d·ª±ng m√¥ h√¨nh **G·ª£i √Ω xe t∆∞∆°ng t·ª±**:
            - S·ª≠ d·ª•ng c√°c ƒë·∫∑c tr∆∞ng t·ª´ m√¥ t·∫£ xe v√† th√¥ng s·ªë k·ªπ thu·∫≠t
            - G·ª£i √Ω c√°c m·∫´u xe t∆∞∆°ng t·ª± v·ªõi xe ƒë∆∞·ª£c ch·ªçn ho·∫∑c theo t·ª´ kh√≥a t√¨m ki·∫øm.

        - X√¢y d·ª±ng m√¥ h√¨nh **Ph√¢n kh√∫c th·ªã tr∆∞·ªùng xe b·∫±ng ph∆∞∆°ng ph√°p ph√¢n c·ª•m**:
            - Ph√¢n c·ª•m th·ªã tr∆∞·ªùng xe m√°y d·ª±a c√°c ƒë·∫∑c tr∆∞ng gi√° xe, tu·ªïi xe, s·ªë km ƒë√£ ch·∫°y, kho·∫£ng gi√° t·ªëi thi·ªÉu, t·ªëi ƒëa.
            - Gi√∫p nh·∫≠n di·ªán c√°c nh√≥m s·∫£n ph·∫©m theo c√°c ph√¢n kh√∫c kh√°c nhau


        ### Ph·∫°m vi tri·ªÉn khai
        - **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† chu·∫©n h√≥a**:
            - Chu·∫©n h√≥a c√°c th√¥ng s·ªë c·ªßa xe.
            - L√†m s·∫°ch d·ªØ li·ªáu v√† chu·∫©n h√≥a tr∆∞·ªùng th√¥ng tin cho m√¥ h√¨nh.

        - **Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng vƒÉn b·∫£n**:
            - S·ª≠ d·ª•ng **TF-IDF Vectorizer** ƒë·ªÉ m√£ h√≥a m√¥ t·∫£ v√† th√¥ng tin k·ªπ thu·∫≠t.
            - T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng b·∫±ng **gensim similarity** v√† **cosine similarity**.
            - Ch·ªçn ph∆∞∆°ng ph√°p cho **ƒëi·ªÉm cao h∆°n** v√† **nghƒ©a ƒë√∫ng h∆°n** ƒë·ªÉ ƒë∆∞a v√†o h·ªá th·ªëng g·ª£i √Ω.

        - **Ph√¢n c·ª•m th·ªã tr∆∞·ªùng (Clustering)**:
            - Th·ª≠ nghi·ªám tr√™n c√°c thu·∫≠t to√°n:  
                - **KMeans**  
                - **Agglomerative Clustering**  
                - **Bisecting KMeans**
            - ƒê√°nh gi√° b·∫±ng inertia, silhouette score, t√≠nh di·ªÖn gi·∫£i.
            - **Ch·ªçn KMeans** v√¨ c√≥ hi·ªáu su·∫•t ·ªïn ƒë·ªãnh, d·ªÖ di·ªÖn gi·∫£i v√† ranh gi·ªõi c·ª•m ph√π h·ª£p h∆°n v·ªõi d·ªØ li·ªáu.

        - **X√¢y d·ª±ng GUI tr√™n Streamlit**:
            - Cho ph√©p ng∆∞·ªùi d√πng *ch·ªçn xe trong danh s√°ch* ho·∫∑c **nh·∫≠p m√¥ t·∫£ xe** ‚Üí tr·∫£ v·ªÅ **danh s√°ch m·∫´u xe t∆∞∆°ng t·ª± c√≥ trong s√†n**.
            - Cho ph√©p **nh·∫≠p t√™n xe** ‚Üí hi·ªÉn th·ªã **xe thu·ªôc c·ª•m/ph√¢n kh√∫c n√†o**.


        ### Thu th·∫≠p d·ªØ li·ªáu
        - B·ªô d·ªØ li·ªáu g·ªìm **7.208 tin ƒëƒÉng** v·ªõi **18 thu·ªôc t√≠nh** (th∆∞∆°ng hi·ªáu, d√≤ng xe, s·ªë km, nƒÉm ƒëƒÉng k√Ω, gi√° ni√™m y·∫øt, m√¥ t·∫£‚Ä¶) ƒë∆∞·ª£c thu th·∫≠p t·ª´ n·ªÅn t·∫£ng **Ch·ª£ T·ªët** (tr∆∞·ªõc ng√†y 01/07/2025).
        - B·ªô d·ªØ li·ªáu bao g·ªìm c√°c th√¥ng tin sau:
            - **id**: s·ªë th·ª© t·ª± c·ªßa s·∫£n ph·∫©m trong b·ªô d·ªØ li·ªáu  
            - **Ti√™u ƒë·ªÅ**: t·ª±a ƒë·ªÅ b√†i ƒëƒÉng b√°n s·∫£n ph·∫©m  
            - **Gi√°**: gi√° b√°n c·ªßa xe m√°y  
            - **Kho·∫£ng gi√° min**: gi√° s√†n ∆∞·ªõc t√≠nh c·ªßa xe m√°y  
            - **Kho·∫£ng gi√° max**: gi√° tr·∫ßn ∆∞·ªõc t√≠nh c·ªßa xe m√°y  
            - **ƒê·ªãa ch·ªâ**: ƒë·ªãa ch·ªâ giao d·ªãch (ph∆∞·ªùng, qu·∫≠n, th√†nh ph·ªë H·ªì Ch√≠ Minh)  
            - **M√¥ t·∫£ chi ti·∫øt**: m√¥ t·∫£ th√™m v·ªÅ s·∫£n ph·∫©m ‚Äî ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t, t√¨nh tr·∫°ng, th√¥ng tin kh√°c  
            - **Th∆∞∆°ng hi·ªáu**: h√£ng s·∫£n xu·∫•t (Honda, Yamaha, Piaggio, SYM‚Ä¶)  
            - **D√≤ng xe**: d√≤ng xe c·ª• th·ªÉ (Air Blade, Vespa, Exciter, LEAD, Vario, ‚Ä¶)  
            - **NƒÉm ƒëƒÉng k√Ω**: nƒÉm ƒëƒÉng k√Ω l·∫ßn ƒë·∫ßu c·ªßa xe  
            - **S·ªë km ƒë√£ ƒëi**: s·ªë kilomet xe ƒë√£ v·∫≠n h√†nh  
            - **T√¨nh tr·∫°ng**: t√¨nh tr·∫°ng hi·ªán t·∫°i (v√≠ d·ª•: ƒë√£ s·ª≠ d·ª•ng)  
            - **Lo·∫°i xe**: Xe s·ªë, Tay ga, Tay c√¥n/Moto  
            - **Dung t√≠ch xe**: dung t√≠ch xi-lanh (v√≠ d·ª•: D∆∞·ªõi 50cc, 50‚Äì100cc, 100‚Äì175cc, ‚Ä¶)  
            - **Xu·∫•t x·ª©**: qu·ªëc gia s·∫£n xu·∫•t (Vi·ªát Nam, ƒê√†i Loan, Nh·∫≠t B·∫£n, ...)  
            - **Ch√≠nh s√°ch b·∫£o h√†nh**: th√¥ng tin b·∫£o h√†nh n·∫øu c√≥  
            - **Tr·ªçng l∆∞·ª£ng**: tr·ªçng l∆∞·ª£ng ∆∞·ªõc t√≠nh c·ªßa xe  
            - **Href**: ƒë∆∞·ªùng d·∫´n t·ªõi b√†i ƒëƒÉng s·∫£n ph·∫©m 

    """)


elif page == "ƒê√°nh gi√° m√¥ h√¨nh v√† B√°o c√°o":    
    st.header("ƒê√°nh gi√° m√¥ h√¨nh v√† B√°o c√°o")  

    st.subheader("I. Th·ªëng k√™ m√¥ t·∫£ s∆° b·ªô")

    # st.markdown("""
    # **1. Th·ªëng k√™ m√¥ t·∫£ s∆° b·ªô** 
    # """)
    st.markdown("""        
    B·ªô d·ªØ li·ªáu g·ªìm **7.208 tin ƒëƒÉng** v·ªõi **18 thu·ªôc t√≠nh** (th∆∞∆°ng hi·ªáu, d√≤ng xe, s·ªë km, nƒÉm ƒëƒÉng k√Ω, gi√° ni√™m y·∫øt, m√¥ t·∫£‚Ä¶) ƒë∆∞·ª£c thu th·∫≠p t·ª´ n·ªÅn t·∫£ng **Ch·ª£ T·ªët** (tr∆∞·ªõc ng√†y 01/07/2025).  
                """)
    # --- V·∫Ω bi·ªÉu ƒë·ªì ---

    # Hi·ªÉn th·ªã 4 bi·ªÉu ƒë·ªì d·∫°ng l∆∞·ªõi 2x2
    col1, col2 = st.columns(2)
    with col1:
        st.image("brand_grouped_count.png")
        st.image("age_bin_stats.png")

    with col2:
        st.image("price_bin_stats.png")
        st.image("mileage_bin_stats.png")

    st.subheader("II. M√¥ h√¨nh g·ª£i √Ω xe m√°y t∆∞∆°ng t·ª±")

    # with open("data/data_motobikes.xlsx", "rb") as f:
    #     st.download_button(
    #         label="üì• T·∫£i xu·ªëng d·ªØ li·ªáu xe m√°y (Excel)",
    #         data=f,
    #         file_name="data_motobikes.xlsx",
    #         mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    #     )
    st.markdown('#### 1. H∆∞·ªõng x·ª≠ l√Ω')
    st.write('''
             - Chu·∫©n h√≥a v√† l√†m s·∫°ch d·ªØ li·ªáu.
             - Chia kho·∫£ng m·ªôt s·ªë ƒë·∫∑c tr∆∞ng ki·ªÉu s·ªë ƒë·ªÉ t·∫°o th√™m c√°c ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i m·ªõi (kho·∫£ng gi√°, t√¨nh tr·∫°ng d·ª±a theo s·ªë km ch·∫°y, tu·ªïi xe, dung t√≠ch xe)
             - Gom c√°c ƒë·∫∑c tr∆∞ng ph√¢n lo·∫°i th√†nh bi·∫øn text
             - L√†m s·∫°ch text v√† tokenize, x√¢y d·ª±ng ma tr·∫≠n t∆∞∆°ng ƒë·ªìng (sparse matrix) gi·ªØa c√°c vƒÉn b·∫£n ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô gi·ªëng nhau
             - T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng b·∫±ng gensim v√† cosine similarity
                 - Tr∆∞·ªùng h·ª£p 1: g·ª£i √Ω xe theo id s·∫£n ph·∫©m ƒë∆∞·ª£c ch·ªçn
                    - Ng∆∞·ªùi d√πng ch·ªçn xe t·ª´ danh s√°ch xe trong t·∫≠p d·ªØ li·ªáu
                    - D·ª±a tr√™n ma tr·∫≠n t∆∞∆°ng ƒë·ªìng, t√¨m c√°c xe c√≥ similarity score cao nh·∫•t.
                    - T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng trung b√¨nh gi·ªØa 5 m·∫´u g·ª£i √Ω cho m·ªôt m·∫´u, sau ƒë√≥ √°p d·ª•ng cho 7000 m·∫´u trong t·∫≠p d·ªØ li·ªáu v√† t√≠nh trung b√¨nh.

                 - Tr∆∞·ªùng h·ª£p 2: g·ª£i √Ω xe theo c·ª•m t·ª´ kh√≥a t√¨m ki·ªÉm (vd: ‚Äúhonda vision xanh d∆∞·ªõi 15 tri·ªáu‚Äù)
                    - Ng∆∞·ªùi d√πng nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm. 
                    - X·ª≠ l√Ω t·ª´ kh√≥a v√† chuy·ªÉn t·ª´ kh√≥a th√†nh vector s·ªë d·ª±a tr√™n t·ª´ ƒëi·ªÉn v√† TF-IDF
                    - T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa t·ª´ kh√≥a v√† t·∫•t c·∫£ xe trong d·ªØ li·ªáu. 
                    - S·∫Øp x·∫øp v√† l·∫•y ra 5 xe g·ª£i √Ω ph√π h·ª£p nh·∫•t.
                    - Cho danh s√°ch 10 c·ª•m t·ª´ kh√≥a t√¨m ki·∫øm. T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng trung b√¨nh gi·ªØa 5 m·∫´u g·ª£i √Ω cho m·ªôt m·∫´u, sau ƒë√≥ √°p d·ª•ng cho 10 c·ª•m t·ª´ tr√™n v√† t√≠nh trung b√¨nh
             ''')
    
    st.markdown('#### 2. K·∫øt qu·∫£')
    st.write('Gi·ªØa 02 m√¥ h√¨nh Gensim v√† Cosine similarity, Cosine similarity, trong c·∫£ 2 tr∆∞·ªùng h·ª£p ch·ªçn xe c√≥ s·∫µn ho·∫∑c t√¨m b·∫±ng t·ª´ kh√≥a, cho ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng trung b√¨nh cao h∆°n so v·ªõi Gensim v√† cho c√°c g·ª£i √Ω s√°t nghƒ©a h∆°n Gensim.\nM√¥ h√¨nh d√πng ƒë·ªÉ d·ª± ƒëo√°n xe trong ·ª©ng d·ª•ng n√†y l√† Cosine similarity.') 

    st.subheader("III. M√¥ h√¨nh ph√¢n kh√∫c xe m√°y b·∫±ng ph∆∞∆°ng ph√°p ph√¢n c·ª•m")
    
    st.markdown('#### 1. X·ª≠ l√Ω d·ªØ li·ªáu')
    st.write('D·ªØ li·ªáu ƒë∆∞·ª£c l√†m s·∫°ch, c√°c ƒë·∫∑c tr∆∞ng bi·∫øn s·ªë li√™n t·ª•c nh∆∞ gi√°, kho·∫£ng gi√° th·∫•p nh·∫•t, l·ªõn nh·∫•t, tu·ªïi xe, s·ªë km ƒë√£ ƒëi ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ t·∫°o m√¥ h√¨nh ph√¢n c·ª•m')

    st.markdown('#### 2. Ph√¢n c·ª•m b·∫±ng c√°c ph∆∞∆°ng ph√°p kh√°c nhau')
    st.write('''
    M√¥ h√¨nh ph√¢n c·ª•m ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n 02 m√¥i tr∆∞·ªùng: m√°y h·ªçc truy·ªÅn th·ªëng (sci-kit learn) v√† PySpark.
    - M√°y h·ªçc truy·ªÅn th·ªëng: KMeans, Bisect Kmeans, Agglomerative clustering
    - PySpark: Kmeans, Bisecting Kmeans, GMM.

    ''')

    st.markdown('#### 3. K·∫øt qu·∫£')
    st.markdown('''
    S·ªë c·ª•m ƒë∆∞·ª£c t·∫°o th√†nh tr√™n m√¥ h√¨nh m√°y h·ªçc truy·ªÅn th·ªëng: **03 c·ª•m**
    S·ªë c·ª•m ƒë∆∞·ª£c t·∫°o th√†nh tr√™n PySpark: **02 c·ª•m**
             
    KMeans tr√™n m√¥i tr∆∞·ªùng m√°y h·ªçc truy·ªÅn th·ªëng cho k·∫øt qu·∫£ silhoutte score cao nh·∫•t v√† k·∫øt qu·∫£ ph√¢n c·ª•m d·ªÖ di·ªÖn gi·∫£i h∆°n.
    
    **Ph√¢n lo·∫°i ph√¢n kh√∫c xe**:                
    1/ C·ª•m 0: Ph√¢n kh√∫c Xe Ph·ªï Th√¥ng ‚Äì Trung c·∫•p (Mid-range Popular Motorcycles): Xe tu·ªïi trung b√¨nh, gi√° v·ª´a ph·∫£i, ph√π h·ª£p ƒë·∫°i ƒëa s·ªë ng∆∞·ªùi mua.   
    2/ C·ª•m 1: Ph√¢n kh√∫c Xe Cao C·∫•p ‚Äì Premium / High-end Motorcycles: R√µ r√†ng l√† c√°c d√≤ng SH, Vespa cao c·∫•p, ph√¢n kh·ªëi l·ªõn, xe m·ªõi ch·∫°y √≠t.          
    3/ C·ª•m 2: Ph√¢n kh√∫c Xe C≈© ‚Äì Ti·∫øt Ki·ªám (Budget Used Motorcycles): Gi√° r·∫ª nh·∫•t, xe tu·ªïi cao, ch·∫°y nhi·ªÅu ‚Äî ph√π h·ª£p kh√°ch c·∫ßn xe r·∫ª ƒë·ªÉ di chuy·ªÉn c∆° b·∫£n.
    ''')
    st.write('''Trong 3 m√¥ h√¨nh ph√¢n c·ª•m KMeans, Bisect KMeans v√† Agglomerate th√¨ KMeans v·ªõi k = 3 cho k·∫øt qu·∫£ ph√¢n c·ª•m t·ªët nh·∫•t.
            n√™n m√¥ h√¨nh ph√¢n c·ª•m xe ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ·ª©ng d·ª•ng n√†y l√† KMeans v·ªõi k = 3.''')

    st.markdown('#### 4. Th·ªëng k√™ theo t·ª´ng c·ª•m:')

    st.write('Tr·ª±c quan h√≥a')
    st.image('pca_clusters.png')

    cluster_summary = (
        df1.groupby('cluster_label')
        .agg(
            count=('cluster_label', 'size'),
            avg_price=('price', 'mean'),
            avg_age=('age', 'mean'),
            avg_mileage=('mileage_km', 'mean')
        )
        .sort_values('cluster_label')
    )


    # Rename the index (cluster_label ‚Üí Nh√£n c·ª•m xe)
    cluster_summary = cluster_summary.rename_axis("Nh√£n c·ª•m xe")

    # Rename columns
    cluster_summary = cluster_summary.rename(columns={
        "count": "S·ªë l∆∞·ª£ng (xe)",
        "avg_price": "Gi√° trung b√¨nh (VND)",
        "avg_age": "Tu·ªïi trung b√¨nh (nƒÉm)",
        "avg_mileage": "S·ªë km trung b√¨nh (km)"
    })

    # Format s·ªë nguy√™n v√† th√™m d·∫•u ph·∫©y
    cluster_summary["Gi√° trung b√¨nh (VND)"] = (
        cluster_summary["Gi√° trung b√¨nh (VND)"]
            .round(0).astype(int)
            .map(lambda x: f"{x:,}")
    )

    cluster_summary["S·ªë km trung b√¨nh (km)"] = (
        cluster_summary["S·ªë km trung b√¨nh (km)"]
            .round(0).astype(int)
            .map(lambda x: f"{x:,}")
    )

    st.dataframe(cluster_summary, width='stretch')


elif page == "G·ª£i √Ω m·∫´u xe t∆∞∆°ng t·ª±":
    st.title("G·ª£i √Ω m·∫´u xe t∆∞∆°ng t·ª±")
    # theo xe c√≥ s·∫µn
    st.header("G·ª£i √Ω xe theo m·∫´u c√≥ s·∫µn")
    selected = st.selectbox("Ch·ªçn m·∫´u xe:", df["title"])

    if st.button("G·ª£i √Ω"):
        similar_titles = get_similar_bikes(selected)
        # Show th√™m ch√≠nh b·∫£ng ghi c·ªßa xe ƒë√£ ch·ªçn
        selected_row = df[df["title"] == selected][
            ["id", "title", "description", "price", "brand", "model",
            "bike_type", "origin", "condition", "mileage_km",
            "registration_year", "engine_capacity"]
        ]

        selected_row = selected_row.rename(columns={
            "id": "id",
            "title": "Ti√™u ƒë·ªÅ",
            "description": "M√¥ t·∫£",
            "price": "Gi√°",
            "brand": "H√£ng",
            "model": "D√≤ng xe",
            "bike_type": "Lo·∫°i xe",
            "origin": "Xu·∫•t x·ª©",
            "condition": "T√¨nh tr·∫°ng",
            "mileage_km": "S·ªë km",
            "registration_year": "NƒÉm ƒëƒÉng k√Ω",
            "engine_capacity": "Dung t√≠ch xe"
        })

        st.markdown("**Xe b·∫°n ƒë√£ ch·ªçn:**")
        st.dataframe(selected_row, width='stretch')

        # Filter dataframe to only the similar bikes
        result_df = df[df["title"].isin(similar_titles)][
            ["id", "title", "description", "price", "brand", "model", "bike_type", "origin", "condition", "mileage_km" ,"registration_year", "engine_capacity"]
        ]
        result_df = result_df.rename(columns={
                "id": "id",
                "title": "Ti√™u ƒë·ªÅ",
                "description": "M√¥ t·∫£",
                "price": "Gi√°",
                "brand": "H√£ng",
                "model": "D√≤ng xe",
                "bike_type": "Lo·∫°i xe",
                "origin": "Xu·∫•t x·ª©",
                "condition": "T√¨nh tr·∫°ng",
                "mileage_km": "S·ªë km",
                "registration_year": "NƒÉm ƒëƒÉng k√Ω",
                "engine_capacity": "Dung t√≠ch xe"
            })
        
        st.markdown("**C√°c m·∫´u xe g·ª£i √Ω:**")
        st.dataframe(result_df, width='stretch')
        
    # theo t·ª´ kh√≥a
    st.header("T√¨m ki·∫øm theo t·ª´ kh√≥a")
    keyword = st.text_input("Nh·∫≠p t·ª´ kh√≥a")
    if st.button("T√¨m xe t∆∞∆°ng t·ª±") and keyword.strip():
        similar_titles = search_by_keyword(keyword)

        # Filter dataframe to only the similar bikes
        result_search_df = df[df["title"].isin(similar_titles)][
            ["id", "title", "description", "price", "brand", "model", "bike_type", "origin", "condition", "mileage_km" ,"registration_year", "engine_capacity"]
        ]
        result_search_df = result_search_df.rename(columns={
                "id": "id",
                "title": "Ti√™u ƒë·ªÅ",
                "description": "M√¥ t·∫£",
                "price": "Gi√°",
                "brand": "H√£ng",
                "model": "D√≤ng xe",
                "bike_type": "Lo·∫°i xe",
                "origin": "Xu·∫•t x·ª©",
                "condition": "T√¨nh tr·∫°ng",
                "mileage_km": "S·ªë km",
                "registration_year": "NƒÉm ƒëƒÉng k√Ω",
                "engine_capacity": "Dung t√≠ch xe"
            })


        st.dataframe(result_search_df, width='stretch')

elif page == "Ph√¢n c·ª•m ph√¢n kh√∫c xe m√°y":
    st.title("Ph√¢n c·ª•m ph√¢n kh√∫c xe m√°y")

    st.markdown("""
    <style>
    .cluster-card {
        padding: 15px;
        border-radius: 12px;
        margin-top: 10px;
        margin-bottom: 15px;
        color: white;
        font-size: 16px;
    }
    .cluster-0 {
        background: linear-gradient(135deg, #4CAF50, #2E7D32);
    }
    .cluster-1 {
        background: linear-gradient(135deg, #1976D2, #0D47A1);
    }
    .cluster-2 {
        background: linear-gradient(135deg, #F57C00, #E65100);
    }
    .cluster-title {
        font-size: 20px;
        font-weight: 700;
        margin-bottom: 5px;
    }
    .cluster-desc {
        font-size: 15px;
    }
    </style>
    """, unsafe_allow_html=True)


    # # st.markdown("""
    # # - **C·ª•m 0:** Xe ph·ªï th√¥ng ‚Äì gi√° r·∫ª, tu·ªïi xe trung b√¨nh, s·ªë km trung b√¨nh ‚Üí **nh√≥m chi·∫øm th·ªã ph·∫ßn l·ªõn nh·∫•t**.
    # # - **C·ª•m 1:** Xe m·ªõi h∆°n ‚Äì gi√° cao h∆°n, ch·∫°y √≠t h∆°n ‚Üí **ph√¢n kh√∫c ch·∫•t l∆∞·ª£ng t·ªët**.
    # # - **C·ª•m 2:** Xe r·∫•t c≈© ‚Äì gi√° th·∫•p nh·∫•t, s·ªë km c·ª±c cao ‚Üí **ph√¢n kh√∫c xu·ªëng c·∫•p ho·∫∑c d·ªØ li·ªáu km kh√¥ng ch√≠nh x√°c**.
    # # """)

    # bike_labels = {0: "Xe ph·ªï th√¥ng gi√° r·∫ª, tu·ªïi xe trung b√¨nh",
    #                1: "Xe t∆∞∆°ng ƒë·ªëi m·ªõi, ph√¢n kh√∫c cao c·∫•p",
    #                2: "Xe c≈© xu·ªëng c·∫•p ho·∫∑c d·ªØ li·ªáu cung c·∫•p kh√¥ng ch√≠nh x√°c"}


    # ====== CLUSTER NEW BIKE ======
    st.header("Ph√¢n c·ª•m xe m·ªõi")

    st.write("Vui l√≤ng nh·∫≠p c√°c th√¥ng s·ªë c·ªßa xe c·∫ßn x√°c ƒë·ªãnh")

    col1, col2 = st.columns(2)

    with col1:
        price = st.number_input("Gi√° xe (VND)", min_value=500_000, step=100_000, value=1_000_000)
        min_price = st.number_input("Kho·∫£ng gi√° min", min_value=500_000, step=100_000, value=800_000)

    with col2:
        max_price = st.number_input("Kho·∫£ng gi√° max", min_value=500_000, step=100_000, value=1_200_000)
        mileage_km = st.number_input("S·ªë km ƒë√£ ƒëi", min_value=0, step=100, value=1000)

    registration_year = st.slider("NƒÉm ƒëƒÉng k√Ω", 1980, 2025)

    if st.button("Ph√¢n c·ª•m"):
        X_new = preprocess_user_input(price, min_price, max_price, mileage_km, registration_year)
        cluster = int(kmeans.predict(X_new)[0])
        st.success(f"Xe thu·ªôc c·ª•m s·ªë **{cluster}**")

        # st.write(bike_labels.get(cluster, "Kh√¥ng c√≥ m√¥ t·∫£ cho c·ª•m n√†y"))

        # ======= HI·ªÇN TH·ªä TH·∫∫ GI·∫¢I TH√çCH C·ª§M THEO K·∫æT QU·∫¢ =======

        cluster_cards = {
            0: """
                <div class="cluster-card cluster-0">
                    <div class="cluster-title">C·ª•m 0 ‚Äì Xe ph·ªï th√¥ng gi√° r·∫ª</div>
                    <div class="cluster-desc">
                        Gi√° th·∫•p ‚Äì tu·ªïi xe trung b√¨nh ‚Äì s·ªë km ch·∫°y v·ª´a ph·∫£i.<br>
                        Ph√¢n kh√∫c xe ph·ªï th√¥ng, ph√π h·ª£p ƒëa s·ªë ng∆∞·ªùi mua.
                    </div>
                </div>
            """,
            1: """
                <div class="cluster-card cluster-1">
                    <div class="cluster-title">C·ª•m 1 ‚Äì Xe cao c·∫•p / √≠t ch·∫°y</div>
                    <div class="cluster-desc">
                        Xe m·ªõi ‚Äì √≠t km ‚Äì gi√° cao.<br>
                        C√°c d√≤ng SH, Vespa, xe cao c·∫•p, t√¨nh tr·∫°ng t·ªët.
                    </div>
                </div>
            """,
            2: """
                <div class="cluster-card cluster-2">
                    <div class="cluster-title">C·ª•m 2 ‚Äì Xe c≈© / gi√° r·∫ª</div>
                    <div class="cluster-desc">
                        Gi√° th·∫•p nh·∫•t ‚Äì km r·∫•t cao ‚Äì tu·ªïi xe l·ªõn.<br>
                        Ph√¢n kh√∫c xe ƒë√£ c≈© ho·∫∑c c√≥ d·∫•u hi·ªáu xu·ªëng c·∫•p.
                    </div>
                </div>
            """
        }

        # Hi·ªÉn th·ªã card t∆∞∆°ng ·ª©ng
        st.markdown(cluster_cards.get(cluster, ""), unsafe_allow_html=True)

